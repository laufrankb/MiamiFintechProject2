{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Prediction with nltk's Kneser-Ney Interpolated Model\n",
    "\n",
    "We'll use the `lm` module in `nltk` to get a sense of how N-Gram language modelling is done.\n",
    "\n",
    "**Source:** The content in this notebook is largely based on [N-gram Language Model with NLTK by Liling Tan](https://www.kaggle.com/alvations/n-gram-language-model-with-nltk/notebook)\n",
    "\n",
    "See also: [language model tutorial in NLTK documentation by Ilia Kurenkov](https://github.com/nltk/nltk/blob/develop/nltk/lm/__init__.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.lm.api import LanguageModel, Smoothing\n",
    "\n",
    "from nltk.lm import MLE # language model\n",
    "from nltk.lm import KneserNeyInterpolated\n",
    "from nltk.lm.smoothing import KneserNey # language model\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.util import pad_sequence, bigrams, ngrams, everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends, flatten, padded_everygram_pipeline\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artists</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrackID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54640449</th>\n",
       "      <td>Jingle Bell Rock</td>\n",
       "      <td>Bobby Helms</td>\n",
       "      <td>Jingle bell, jingle bell, jingle bell rock Jin...</td>\n",
       "      <td>['rock', 'swing', 'ring', 'snowing', 'blowing'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568180108</th>\n",
       "      <td>Fancy Like</td>\n",
       "      <td>Walker Hayes</td>\n",
       "      <td>Ayy My girl is bangin' She's so low maintenanc...</td>\n",
       "      <td>['ayy', 'girl', 'bangin', 'shes', 'low', 'main...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52815945</th>\n",
       "      <td>Enchanted</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>There I was again tonight Forcing laughter, fa...</td>\n",
       "      <td>['tonight', 'forcing', 'laughter', 'faking', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463807349</th>\n",
       "      <td>Old Town Road (Remix)</td>\n",
       "      <td>Lil Nas X Feat. Billy Ray Cyrus</td>\n",
       "      <td>Oh, oh-oh Oh  Yeah, I'm gon' take my horse to ...</td>\n",
       "      <td>['yeah', 'take', 'horse', 'old', 'town', 'road...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559530353</th>\n",
       "      <td>Thinking 'Bout You</td>\n",
       "      <td>Dustin Lynch Feat. MacKenzie Porter</td>\n",
       "      <td>Well, look who it is Last call I thought I'd g...</td>\n",
       "      <td>['well', 'look', 'last', 'call', 'thought', 'h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Track Name                              Artists  \\\n",
       "TrackID                                                                 \n",
       "54640449        Jingle Bell Rock                          Bobby Helms   \n",
       "568180108             Fancy Like                         Walker Hayes   \n",
       "52815945               Enchanted                         Taylor Swift   \n",
       "463807349  Old Town Road (Remix)      Lil Nas X Feat. Billy Ray Cyrus   \n",
       "559530353     Thinking 'Bout You  Dustin Lynch Feat. MacKenzie Porter   \n",
       "\n",
       "                                                      Lyrics  \\\n",
       "TrackID                                                        \n",
       "54640449   Jingle bell, jingle bell, jingle bell rock Jin...   \n",
       "568180108  Ayy My girl is bangin' She's so low maintenanc...   \n",
       "52815945   There I was again tonight Forcing laughter, fa...   \n",
       "463807349  Oh, oh-oh Oh  Yeah, I'm gon' take my horse to ...   \n",
       "559530353  Well, look who it is Last call I thought I'd g...   \n",
       "\n",
       "                                                      Tokens  \n",
       "TrackID                                                       \n",
       "54640449   ['rock', 'swing', 'ring', 'snowing', 'blowing'...  \n",
       "568180108  ['ayy', 'girl', 'bangin', 'shes', 'low', 'main...  \n",
       "52815945   ['tonight', 'forcing', 'laughter', 'faking', '...  \n",
       "463807349  ['yeah', 'take', 'horse', 'old', 'town', 'road...  \n",
       "559530353  ['well', 'look', 'last', 'call', 'thought', 'h...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Lyrics Dataframe\n",
    "df = pd.read_csv('lyrics_df.csv').set_index('TrackID')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Modeling with MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize lyrics corpus\n",
    "lyrics_corpus = list(df['Lyrics'].apply(word_tokenize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the tokenized text for 4-grams language modelling\n",
    "n = 4\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, lyrics_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and fit the model\n",
    "country_model = MLE(n) # Lets train a 4-grams model\n",
    "country_model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the generated tokens to make it human-like.\n",
    "\n",
    "detokenize = TreebankWordDetokenizer().detokenize\n",
    "\n",
    "def generate_sent(model, num_words, random_seed):\n",
    "    \"\"\"\n",
    "    :param model: An ngram language model from `nltk.lm.model`.\n",
    "    :param num_words: Max no. of words to generate.\n",
    "    :param random_seed: Seed value for random.\n",
    "    \"\"\"\n",
    "    content = []\n",
    "    for token in model.generate(num_words, random_seed=random_seed):\n",
    "        if token == '<s>':\n",
    "            continue\n",
    "        if token == '</s>':\n",
    "            break\n",
    "        content.append(token)\n",
    "    return detokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", at the end of the day, y'all I'm just tryna keep my daughters off the pole And my sons out of jail (sons out of jail (sons out of jail Tryna get to church so I don't go to hell (I don't know why, don't give a fuck if it's your b-day I hand it off like a relay In Beverly Hills straight covered in grease I'm a lady Men's shirts, short skirts Oh, oh, I wannacome back as a country boy No, there ain't no better life if you ask me If my neck don't come out red, then Lord, just keep me dead 'Cause a country boy is all that I know how to be Yeah, a country boy's all that I'm like a Marlboro man so I kick on back Wish I could quit you, but I lost all control And I need you now And I don't know how I can do without I just need you now (Whoa-whoa) Guess I rather hurt than feel nothing at all It's a rich man's game No matter what they call it And you spend your last dime to put a rock on her hand I hope she's wilder than your wildest Dreams, she's walkin' back to me 'Cause don't nothing taste better than free Yeah, to feel the way I feel And man, I feel cheap I feel used, I feel like a woman\n"
     ]
    }
   ],
   "source": [
    "# Predict text\n",
    "print(generate_sent(country_model, num_words=280, random_seed=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Modeling with Kneser-Ney Interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" NOT WORKING YET \"\"\"\n",
    "# Train and fit the model\n",
    "country_model_kn = KneserNeyInterpolated(n) # Lets train a 4-grams model\n",
    "\n",
    "# ^^^^^ the above probably needs counter and vocab parameters to work\n",
    "\n",
    "country_model_kn.fit(train_data, padded_sents)\n",
    "len(country_model_kn.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't choose from empty population",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21136/51985414.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# print(generate_sent(country_model_kn, num_words=10, random_seed=3))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcountry_model_kn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\MachLearn\\lib\\site-packages\\nltk\\lm\\api.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, num_words, text_seed, random_seed)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             generated.append(\n\u001b[1;32m--> 224\u001b[1;33m                 self.generate(\n\u001b[0m\u001b[0;32m    225\u001b[0m                     \u001b[0mnum_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                     \u001b[0mtext_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_seed\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachLearn\\lib\\site-packages\\nltk\\lm\\api.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, num_words, text_seed, random_seed)\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[1;31m# - turns Mapping into Sequence which `_weighted_choice` expects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m             return _weighted_choice(\n\u001b[0m\u001b[0;32m    216\u001b[0m                 \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachLearn\\lib\\site-packages\\nltk\\lm\\api.py\u001b[0m in \u001b[0;36m_weighted_choice\u001b[1;34m(population, weights, random_generator)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \"\"\"\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can't choose from empty population\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The number of weights does not match the population\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can't choose from empty population"
     ]
    }
   ],
   "source": [
    "# Predict text\n",
    "print(generate_sent(country_model_kn, num_words=10, random_seed=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b24175bddfaec99ad0d13c7f3c62ff2d27640d666ee47e274bb34432b073efd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('MachLearn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
